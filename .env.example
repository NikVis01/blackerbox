# Blackbox Server Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# REQUIRED: HuggingFace Configuration
# =============================================================================

# HuggingFace API Token
# Get your token from: https://huggingface.co/settings/tokens
# Required for model deployment via POST /deploy
HF_TOKEN=hf_xxxxxxxxxxxxx

# =============================================================================
# OPTIONAL: Model Deployment Configuration
# =============================================================================

# Maximum number of concurrent models that can be deployed
# Default: 3
# Set this based on your GPU memory capacity
MAX_CONCURRENT_MODELS=3

# GPU Type Override
# Options: T4, A100, H100, L40
# If not set, will auto-detect via nvidia-smi
# Leave empty for auto-detection
GPU_TYPE=

# =============================================================================
# Notes
# =============================================================================
#
# - The .env file is automatically loaded from the current directory
# - Environment variables can also be set in ~/.env (home directory)
# - System environment variables take precedence over .env file values
# - All values in this file are optional except HF_TOKEN (if deploying models)
#
# For model deployment:
#   - HF_TOKEN is required for POST /deploy endpoint
#   - Can be provided in request body instead of .env file
#
# For optimization:
#   - Models are tracked automatically via VRAM monitoring
#   - Use POST /optimize to restart overallocated models
#   - Optimization uses peak VRAM usage to recalculate max_gpu_utilization
